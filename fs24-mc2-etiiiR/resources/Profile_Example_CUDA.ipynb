{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NoV0YWpWeX0Y",
    "outputId": "709250cb-0d42-4bbc-9708-b8aefef07c54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun  3 14:13:19 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.86                 Driver Version: 551.86         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080      WDDM  |   00000000:0B:00.0  On |                  N/A |\n",
      "| 57%   47C    P5             47W /  370W |    1824MiB /  10240MiB |     37%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     12824    C+G   ...-Agent\\app-0.4.25\\Postman Agent.exe      N/A      |\n",
      "|    0   N/A  N/A     21184    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     25556    C+G   ...am Files\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     30600    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     31940    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     33032    C+G   ...Files\\Sony\\INZONE Hub\\INZONEHub.exe      N/A      |\n",
      "|    0   N/A  N/A     36540    C+G   ...7.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     44716    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     45844    C+G   ...480_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A     47932    C+G   ...20.0_x64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A     54012    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     57160    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     63164    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     68284    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     71352    C+G   ...on\\125.0.2535.79\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     71864    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
      "|    0   N/A  N/A     72792    C+G   ...esktop\\app-3.3.18\\GitHubDesktop.exe      N/A      |\n",
      "|    0   N/A  N/A     78000    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     98188    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVVwNqwjeYL0",
    "outputId": "da02e775-bfe9-427c-d9f7-82674e8feae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reduce.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile reduce.cu\n",
    "/* This program will performe a reduce vectorA (size N)\n",
    "* with the + operation.\n",
    "+---------+ \n",
    "|111111111| \n",
    "+---------+\n",
    "     |\n",
    "     N\n",
    "\n",
    "vectorA   = all Ones\n",
    "N = Sum of vectorA\n",
    "*/\n",
    "#include <iostream>\n",
    "#include <sstream>\n",
    "#include <stdlib.h>\n",
    "#include \"cuda_runtime.h\"\n",
    "#include \"device_launch_parameters.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "\n",
    "// CUDA macro wrapper for checking errors\n",
    "#define gpuErrCheck(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
    "inline void gpuAssert(cudaError_t code, const char* file, int line, bool abort = true)\n",
    "{\n",
    "    if (code != cudaSuccess)\n",
    "    {\n",
    "        std::cout << \"GPUassert: \" << cudaGetErrorString(code) << \" \" << file << \" \" << line << std::endl;\n",
    "        if (abort)\n",
    "        {\n",
    "            exit(code);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// CPU reduce\n",
    "void reduce(int* vectorA, int* sum, int size)\n",
    "{\n",
    "    sum[0] = 0;\n",
    "    for (int i = 0; i < size; i++)\n",
    "        sum[0] += vectorA[i];\n",
    "}\n",
    "\n",
    "\n",
    "// EXERCISE\n",
    "// Read: https://developer.nvidia.com/blog/faster-parallel-reductions-kepler/\n",
    "// Implement the reduce kernel based on the information\n",
    "// of the Nvidia blog post.\n",
    "// Implement both options, using no shared mem at all but global atomics\n",
    "// and using shared mem for the seconds recution phase.\n",
    "__global__ void cudaEvenFasterReduceAddition() {\n",
    "    //ToDo\n",
    "}\n",
    "\n",
    "\n",
    "// Already optimized reduce kernel using shared memory.\n",
    "__global__ void cudaReduceAddition(int* vectorA, int* sum)\n",
    "{\n",
    "    int globalIdx = 2 * blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    extern __shared__ int shmArray[];\n",
    "\n",
    "    shmArray[threadIdx.x] = vectorA[globalIdx];\n",
    "    shmArray[threadIdx.x + blockDim.x] = vectorA[globalIdx + blockDim.x];\n",
    "\n",
    "    for (int stride = blockDim.x; stride; stride >>= 1) {\n",
    "        if (threadIdx.x < stride) {\n",
    "            shmArray[threadIdx.x] += shmArray[threadIdx.x + stride];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (threadIdx.x == 0) {\n",
    "        sum[blockIdx.x] = shmArray[0];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// Compare result vectors\n",
    "int compareResultVec(int* vectorCPU, int* vectorGPU, int size)\n",
    "{\n",
    "    int error = 0;\n",
    "    for (int i = 0; i < size; i++)\n",
    "    {\n",
    "        error += abs(vectorCPU[i] - vectorGPU[i]);\n",
    "    }\n",
    "    if (error == 0)\n",
    "    {\n",
    "        cout << \"No errors. All good!\" << endl;\n",
    "        return 0;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        cout << \"Accumulated error: \" << error << endl;\n",
    "        return -1;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    // Define the size of the vector: 1048576 elements\n",
    "    const int N = 1 << 20;\n",
    "    const int NBR_BLOCK = 512;\n",
    "\n",
    "    // Allocate and prepare input\n",
    "    int* hostVectorA = new int[N];\n",
    "    int hostSumCPU[1];\n",
    "    int hostSumGPU[1];\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        hostVectorA[i] = 1;\n",
    "    }\n",
    "\n",
    "    // Alloc N times size of int at address of deviceVector[A-C]\n",
    "    int* deviceVectorA;\n",
    "    int* deviceSum;\n",
    "    gpuErrCheck(cudaMalloc(&deviceVectorA, N * sizeof(int)));\n",
    "    gpuErrCheck(cudaMalloc(&deviceSum, NBR_BLOCK* sizeof(int)));\n",
    "\n",
    "    // Copy data from host to device\n",
    "    gpuErrCheck(cudaMemcpy(deviceVectorA, hostVectorA, N * sizeof(int), cudaMemcpyHostToDevice));\n",
    "\n",
    "    // Run the vector kernel on the CPU\n",
    "    reduce(hostVectorA, hostSumCPU, N);\n",
    "\n",
    "    // Run kernel on all elements on the GPU\n",
    "    cudaReduceAddition <<<NBR_BLOCK, 1024, 2 * 1024 * sizeof(int)>>> (deviceVectorA, deviceSum);\n",
    "    gpuErrCheck(cudaPeekAtLastError());\n",
    "    cudaReduceAddition <<<1, NBR_BLOCK / 2, NBR_BLOCK * sizeof(int) >> > (deviceSum, deviceSum);\n",
    "    gpuErrCheck(cudaPeekAtLastError());\n",
    "\n",
    "    // Copy the result stored in device_y back to host_y\n",
    "    gpuErrCheck(cudaMemcpy(hostSumGPU, deviceSum, sizeof(int), cudaMemcpyDeviceToHost));\n",
    "\n",
    "    // Check for errors\n",
    "    auto isValid = compareResultVec(hostSumCPU, hostSumGPU, 1);\n",
    "\n",
    "    // Free memory on device\n",
    "    gpuErrCheck(cudaFree(deviceVectorA));\n",
    "    gpuErrCheck(cudaFree(deviceSum));\n",
    "\n",
    "    // Free memory on host\n",
    "    delete[] hostVectorA;\n",
    "\n",
    "    return isValid;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXRAf_-9lub9"
   },
   "source": [
    "**Attention:** If you get a K80, you should compile it like this:\n",
    "`!nvcc -arch=sm_37 -o reduce reduce.cu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4lLHNUzHef9q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc fatal   : Cannot find compiler 'cl.exe' in PATH\n"
     ]
    }
   ],
   "source": [
    "!nvcc -o reduce reduce.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57IzTD97eqDX",
    "outputId": "6aceadaf-3698-4c1a-e9d9-0d69d0c4535c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'.' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!./reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7p-YpNLPnMEV"
   },
   "source": [
    "**Profiling on old GPU (K80)**\n",
    "\n",
    "*   `!nvprof --print-gpu-trace ./reduce`\n",
    "*   `!nvprof --analysis-metrics -o reduce_out.nvprof ./reduce`\n",
    "*   --> Use the Visual Profiler\n",
    "\n",
    "**Profiling on newer GPUs**\n",
    "\n",
    "*   `!nsys profile -f true -o reduce_out -t cuda ./reduce`\n",
    "*   `!nsys stats --report gputrace reduce.qdrep`\n",
    "*   `!nsys stats reduce.qdrep`\n",
    "*   `!ncu -f -o reduce --set full ./reduce`\n",
    "*   --> Nvidia Nsight Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPbbe5AaUU4Y"
   },
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FszJbI5nVjz",
    "outputId": "7e836e7a-2ad7-41ab-99a2-906a6fec252f"
   },
   "outputs": [],
   "source": [
    "!nvprof --print-gpu-trace ./reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZrPgfUgn1DX",
    "outputId": "5459d5d2-fdad-4f19-b5c5-49f516d13d1a"
   },
   "outputs": [],
   "source": [
    "!nvprof --analysis-metrics -o reduce_out.nvprof ./reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTzsnXS4UYtc"
   },
   "source": [
    "Use the file *reduce_out.nvprof* with the visual profiler of Nvidia, which you have locally installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lrwzKmITUmJp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU context switches trace requires administrative privileges, disabling.\n",
      "WARNING: CPU sampling requires administrative privileges, disabling.\n",
      "Executable not found in current directory or standard search paths\n"
     ]
    }
   ],
   "source": [
    "!nsys profile -f true --stats=true -o reduce_out -t cuda ./reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Specified input file (reduce_out.qdrep) does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "usage: nsys stats [<args>] <input-file>\n",
      "Try 'nsys stats --help' for more information.\n"
     ]
    }
   ],
   "source": [
    "!nsys stats reduce_out.qdrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
